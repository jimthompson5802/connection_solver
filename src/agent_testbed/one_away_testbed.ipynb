{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python311.zip\n",
      "/usr/local/lib/python3.11\n",
      "/usr/local/lib/python3.11/lib-dynload\n",
      "\n",
      "/usr/local/lib/python3.11/site-packages\n",
      "/workspaces/connection_solver/src/agent\n",
      "/workspaces/connection_solver/src/agent\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import hashlib\n",
    "import itertools\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# import cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Import the 'rag_tools' module from the 'agent' directory\n",
    "current_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the 'agent' directory to the sys.path\n",
    "other_dir = os.path.join(project_dir, 'agent')\n",
    "sys.path.append(other_dir)\n",
    "\n",
    "# confirm the 'agent' directory is in the sys.path\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "\n",
    "from embedvec_tools import choose_embedvec_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/openai/api_key.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_id(group: List[str]) -> str:\n",
    "        return hashlib.md5(\"\".join(sorted(group)).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vocab = \"word_list6.pkl\"\n",
    "\n",
    "# load the vocabulary\n",
    "df = pd.read_pickle(test_vocab)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConnectionGroup:\n",
    "    group_metric: float = field(default=0.0, metadata={\"help\": \"Average cosine similarity of all combinations of words in the group\"})\n",
    "    group_metric_min: float = field(default=0.0, metadata={\"help\": \"Minimum cosine similarity of all combinations of words in the group\"})\n",
    "    group_metric_max: float = field(default=0.0, metadata={\"help\": \"Maximum cosine similarity of all combinations of words in the group\"})\n",
    "    group_metric_std: float = field(default=0.0, metadata={\"help\": \"Standard deviation of cosine similarity of all combinations of words in the group\"})\n",
    "    root_word: str = field(default=\"\", metadata={\"help\": \"Root word of the group\"})\n",
    "    candidate_pairs: list = field(default_factory=list, metadata={\"help\": \"List of candidate word with definition\"})\n",
    "    group_id: Optional[str] = field(default=None, metadata={\"help\": \"Checksum identifer for the group\"})\n",
    "\n",
    "    def add_entry(self, word, connection):\n",
    "        if len(self.candidate_pairs) < 4:\n",
    "            self.candidate_pairs.append((word, connection))\n",
    "            if len(self.candidate_pairs) == 4:\n",
    "                self.group_id = self._compute_group_id()\n",
    "        else:\n",
    "            raise ValueError(\"Group is full, cannot add more entries\")          \n",
    "\n",
    "    def get_candidate_words(self):\n",
    "        sorted_pairs = sorted(self.candidate_pairs, key=lambda x:x[0])\n",
    "        return [x[0] for x in sorted_pairs]\n",
    "    \n",
    "    def get_candidate_connections(self):\n",
    "        sorted_pairs = sorted(self.candidate_pairs, key=lambda x:x[0])\n",
    "\n",
    "        # strip the part of speech tag at the beginning of the connection, which looks like \"noun:\" or \"verb:\" etc.\n",
    "        # find the first colon and take the substring after it\n",
    "        stripped_connections = [x[1].split(':', 1)[1].strip() if ':' in x[1] else x[1] for x in sorted_pairs]\n",
    "\n",
    "        return stripped_connections\n",
    "    \n",
    "    def _compute_group_id(self):\n",
    "        return hashlib.md5(\"\".join(self.get_candidate_words()).encode()).hexdigest()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return_string = f\"group metrics: {self.group_metric}, {self.group_metric_min}, {self.group_metric_max},{self.group_metric_std}\\n\"\n",
    "        return_string += f\"root word: {self.root_word}, group id: {self.group_id}\\n\"\n",
    "        return_string += f\"candidate group: {self.get_candidate_words()}\\n\"\n",
    "        for connection in self.get_candidate_connections():\n",
    "            return_string += f\"\\t{connection}\\n\"\n",
    "\n",
    "        return return_string\n",
    "    \n",
    "    # method to determine if the group is equal to another group\n",
    "    def __eq__(self, other):\n",
    "        return set(self.get_candidate_words()) == set(other.get_candidate_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A small, hard seed of a cereal plant, su...</td>\n",
       "      <td>[-0.012600858695805073, 0.012784576043486595, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A single small particle or piece, such a...</td>\n",
       "      <td>[0.020823834463953972, -0.024603812023997307, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: The texture or pattern of fibers in wood...</td>\n",
       "      <td>[-0.007330888416618109, -0.0005790892755612731...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: An individual element or component withi...</td>\n",
       "      <td>[0.025177670642733574, 0.00015151509433053434,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A unit of weight in the avoirdupois syst...</td>\n",
       "      <td>[0.01975935325026512, -0.03580138459801674, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A characteristic or essential quality.</td>\n",
       "      <td>[0.019196202978491783, -0.0004823370254598558,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A small amount or degree, e.g., 'a grain...</td>\n",
       "      <td>[-0.0131387859582901, 0.02310130186378956, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: The alignment or direction of the fibers...</td>\n",
       "      <td>[-0.017064416781067848, 0.010718798264861107, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grain</td>\n",
       "      <td>verb: To form into grains or granules.</td>\n",
       "      <td>[-0.01263611763715744, 0.011555520817637444, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grain</td>\n",
       "      <td>verb: To give a texture resembling grain to a ...</td>\n",
       "      <td>[-0.012740093283355236, 0.005322569981217384, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grain</td>\n",
       "      <td>adjective: Relating to or resembling grain.</td>\n",
       "      <td>[-0.040710438042879105, 0.025842908769845963, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>drain</td>\n",
       "      <td>noun: A pipe or channel that carries away wast...</td>\n",
       "      <td>[0.029757274314761162, 0.013937382027506828, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drain</td>\n",
       "      <td>noun: An instance of water or liquid flowing o...</td>\n",
       "      <td>[0.014105943962931633, 0.05353502556681633, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>drain</td>\n",
       "      <td>noun: A reduction or depletion of resources or...</td>\n",
       "      <td>[0.019143683835864067, 0.049778468906879425, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>drain</td>\n",
       "      <td>verb: To cause liquid to flow away from someth...</td>\n",
       "      <td>[0.0020029456354677677, 0.010084928013384342, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word                                         definition  \\\n",
       "0   grain  noun: A small, hard seed of a cereal plant, su...   \n",
       "1   grain  noun: A single small particle or piece, such a...   \n",
       "2   grain  noun: The texture or pattern of fibers in wood...   \n",
       "3   grain  noun: An individual element or component withi...   \n",
       "4   grain  noun: A unit of weight in the avoirdupois syst...   \n",
       "5   grain       noun: A characteristic or essential quality.   \n",
       "6   grain  noun: A small amount or degree, e.g., 'a grain...   \n",
       "7   grain  noun: The alignment or direction of the fibers...   \n",
       "8   grain             verb: To form into grains or granules.   \n",
       "9   grain  verb: To give a texture resembling grain to a ...   \n",
       "10  grain        adjective: Relating to or resembling grain.   \n",
       "11  drain  noun: A pipe or channel that carries away wast...   \n",
       "12  drain  noun: An instance of water or liquid flowing o...   \n",
       "13  drain  noun: A reduction or depletion of resources or...   \n",
       "14  drain  verb: To cause liquid to flow away from someth...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.012600858695805073, 0.012784576043486595, ...  \n",
       "1   [0.020823834463953972, -0.024603812023997307, ...  \n",
       "2   [-0.007330888416618109, -0.0005790892755612731...  \n",
       "3   [0.025177670642733574, 0.00015151509433053434,...  \n",
       "4   [0.01975935325026512, -0.03580138459801674, -0...  \n",
       "5   [0.019196202978491783, -0.0004823370254598558,...  \n",
       "6   [-0.0131387859582901, 0.02310130186378956, -0....  \n",
       "7   [-0.017064416781067848, 0.010718798264861107, ...  \n",
       "8   [-0.01263611763715744, 0.011555520817637444, -...  \n",
       "9   [-0.012740093283355236, 0.005322569981217384, ...  \n",
       "10  [-0.040710438042879105, 0.025842908769845963, ...  \n",
       "11  [0.029757274314761162, 0.013937382027506828, -...  \n",
       "12  [0.014105943962931633, 0.05353502556681633, -0...  \n",
       "13  [0.019143683835864067, 0.049778468906879425, -...  \n",
       "14  [0.0020029456354677677, 0.010084928013384342, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_words(df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Generate a list of candidate word groups based on cosine similarity of their embeddings.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing words and their corresponding embeddings. Dataframe should have two columns: 'word', 'definition' and 'embedding', in that order.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique candidate word groups sorted by their group metric in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "    candidate_list = []\n",
    "\n",
    "    # create cosine similarity matrix for all pairs of the vectors\n",
    "    cosine_similarities = cosine_similarity(df['embedding'].tolist())\n",
    "    print(cosine_similarities.shape)\n",
    "\n",
    "    # for each row in the cosine similarity matrix, sort by the cosine similarity\n",
    "    sorted_cosine_similarites = np.argsort(cosine_similarities, axis=1)\n",
    "    print(sorted_cosine_similarites.shape)\n",
    "\n",
    "    # group of words that are most similar to each other\n",
    "    for r in range(df.shape[0]):\n",
    "\n",
    "        # get the top 3 closest words that are not the same as the current word and are not already connected\n",
    "        connected_words = set()\n",
    "        top3 = []\n",
    "        for i in range(sorted_cosine_similarites.shape[1]-2, 0, -1):\n",
    "            c = sorted_cosine_similarites[r, i]\n",
    "            \n",
    "            # make sure the word is not already connected and not the current word\n",
    "            if df.iloc[c, 0] not in connected_words and df.iloc[c, 0] != df.iloc[r, 0]:\n",
    "                connected_words.add(df.iloc[c, 0])\n",
    "                top3.append(c)\n",
    "            if len(connected_words) == 3:\n",
    "                break   \n",
    "\n",
    "        # create candidate group for the current word and the top 3 closest words\n",
    "        if df.iloc[r, 0] not in connected_words and len(connected_words) == 3:\n",
    "            candidate_group = ConnectionGroup()\n",
    "            candidate_group.root_word = df.iloc[r, 0]\n",
    "            candidate_group.add_entry(df.iloc[r, 0], df.iloc[r, 1])\n",
    "            \n",
    "            for c in top3:\n",
    "                candidate_group.add_entry(df.iloc[c, 0], df.iloc[c, 1])\n",
    "\n",
    "            combinations = list(itertools.combinations([r] + top3, 2))\n",
    "            candidate_group.group_metric= np.array([cosine_similarities[r, c] for r,c in combinations]).mean()\n",
    "            candidate_group.group_metric_min = np.array([cosine_similarities[r, c] for r,c in combinations]).min()\n",
    "            candidate_group.group_metric_max = np.array([cosine_similarities[r, c] for r,c in combinations]).max()\n",
    "            candidate_group.group_metric_std = np.array([cosine_similarities[r, c] for r,c in combinations]).std()\n",
    "\n",
    "            candidate_list.append(candidate_group)\n",
    "\n",
    "    # sort the candidate list by the group metric in descending order\n",
    "    candidate_list.sort(key=lambda x: x.group_metric, reverse=True)\n",
    "\n",
    "    # remove duplicate groups\n",
    "    found_groups = set()\n",
    "    unique_candidate_list = []\n",
    "    for candidate in candidate_list:\n",
    "        if candidate.group_id not in found_groups:\n",
    "            unique_candidate_list.append(candidate)\n",
    "            found_groups.add(candidate.group_id)\n",
    "\n",
    "    return unique_candidate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grain',\n",
       " 'drain',\n",
       " 'total',\n",
       " 'cube',\n",
       " 'syrup',\n",
       " 'shred',\n",
       " 'signature',\n",
       " 'sap',\n",
       " 'jam',\n",
       " 'tax',\n",
       " 'powder',\n",
       " 'rock',\n",
       " 'empty',\n",
       " 'groove',\n",
       " 'tip',\n",
       " 'exhaust']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recommendation(df: pd.DataFrame) -> Tuple[List[str], Dict[str, Any]]:\n",
    "    candidate_list = get_candidate_words(df)\n",
    "    print(len(candidate_list))\n",
    "    # list_to_validate = \"\\n\".join([str(x) for x in candidate_list[:5]])\n",
    "    # recommended_group = choose_embedvec_item(list_to_validate)\n",
    "    # print(recommended_group)\n",
    "    # recommended_words = recommended_group[\"candidate_group\"]\n",
    "    # # print(recommended_words)\n",
    "    \n",
    "    return candidate_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage:\n",
    "while df.word.unique().size > 0:\n",
    "    rw = find_recommendation(df)\n",
    "    print(f\"using these words {rw}, type {type(rw)}\")\n",
    "\n",
    "    # remove the words from the dataframe\n",
    "    df = df[~df.word.isin(rw)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.word.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "candidate_list = get_candidate_words(df)\n",
    "for candidate in candidate_list:\n",
    "    if candidate.group_id in answers:\n",
    "        print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 130)\n",
      "(130, 130)\n",
      "89\n",
      " type <class 'list'>,\n",
      "using these words [group metrics: 0.6668112426310061, 0.4548451189813011, 0.8192041282045356,0.14605518688265232\n",
      "root word: exhaust, group id: fb7dc317dbf562c0a79420118f823f50\n",
      "candidate group: ['drain', 'exhaust', 'sap', 'total']\n",
      "\tTo deplete or exhaust resources, energy, or vitality.\n",
      "\tTo drain of resources or strength; to wear out completely.\n",
      "\tTo drain someone of energy or vitality.\n",
      "\tTo destroy or wreck completely, especially in reference to vehicles.\n",
      ", group metrics: 0.6468176127874155, 0.4677014117419175, 0.8192041282045356,0.15792040975947702\n",
      "root word: tax, group id: 1832357b3b2db5fa0d8e1d7bbc25a7ab\n",
      "candidate group: ['drain', 'exhaust', 'sap', 'tax']\n",
      "\tTo deplete or exhaust resources, energy, or vitality.\n",
      "\tTo drain of resources or strength; to wear out completely.\n",
      "\tTo drain someone of energy or vitality.\n",
      "\tTo make heavy demands on someone’s resources or abilities, e.g., 'The difficult project taxed his patience.'\n",
      ", group metrics: 0.6410907016394721, 0.4531656157622107, 0.8192041282045356,0.1636909237258528\n",
      "root word: sap, group id: 03fcf0339c681de880eaedad3c6ce82a\n",
      "candidate group: ['drain', 'empty', 'exhaust', 'sap']\n",
      "\tTo deplete or exhaust resources, energy, or vitality.\n",
      "\tto discharge or pour out\n",
      "\tTo drain of resources or strength; to wear out completely.\n",
      "\tTo drain someone of energy or vitality.\n",
      ", group metrics: 0.6410013668912845, 0.6186868245856227, 0.6851405493212731,0.021962175720038595\n",
      "root word: cube, group id: 2eb843fc0c3b5de51216fd6d6a38c385\n",
      "candidate group: ['cube', 'grain', 'shred', 'tip']\n",
      "\tA small piece of something, typically food, cut into a square shape.\n",
      "\tA single small particle or piece, such as of sand or salt.\n",
      "\tA small, thin piece that has been torn or cut from something larger, like a shred of paper.\n",
      "\tA small piece or end of something, like the tip of an iceberg.\n",
      ", group metrics: 0.6122381498040032, 0.5428332531233181, 0.7107942184505749,0.05206276478306876\n",
      "root word: shred, group id: 6b13db1e892c81417d2958289ab4546a\n",
      "candidate group: ['cube', 'grain', 'powder', 'shred']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo form into grains or granules.\n",
      "\tTo reduce a substance to fine particles by crushing or grinding.\n",
      "\tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.\n",
      ", group metrics: 0.5832894195098461, 0.5248302241774248, 0.7107942184505749,0.06136819777610336\n",
      "root word: groove, group id: 41671fee7635abfcb48bae2adc5e7c97\n",
      "candidate group: ['cube', 'grain', 'groove', 'shred']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo form into grains or granules.\n",
      "\tTo cut or form a groove in something.\n",
      "\tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.\n",
      ", group metrics: 0.5821507294843583, 0.4505040318022098, 0.7107942184505749,0.08023682560911559\n",
      "root word: cube, group id: 9af537d76b7547704df3eaec8faee430\n",
      "candidate group: ['cube', 'groove', 'powder', 'shred']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo cut or form a groove in something.\n",
      "\tTo reduce a substance to fine particles by crushing or grinding.\n",
      "\tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.\n",
      ", group metrics: 0.5665175571549194, 0.4505040318022098, 0.6296911868869787,0.05713679804145699\n",
      "root word: grain, group id: 9b3b952f608b07a1a0e68b3661689b8e\n",
      "candidate group: ['cube', 'grain', 'groove', 'powder']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo form into grains or granules.\n",
      "\tTo cut or form a groove in something.\n",
      "\tTo reduce a substance to fine particles by crushing or grinding.\n",
      ", group metrics: 0.549165592441618, 0.3892849462047492, 0.6821830908122153,0.12029488563244665\n",
      "root word: exhaust, group id: 41d44c7c3d219f1d35810aea83df36c4\n",
      "candidate group: ['drain', 'empty', 'exhaust', 'jam']\n",
      "\tTo remove liquid from something by causing it to flow out.\n",
      "\tto discharge or pour out\n",
      "\tTo let out or expel air or gas from a container or space.\n",
      "\tto squeeze or pack tightly into a space\n",
      ", group metrics: 0.5418542527821628, 0.45534444516200423, 0.6151571886484759,0.050598497770272303\n",
      "root word: jam, group id: fa7836ec92c593516be38a5b1cf8ec2c\n",
      "candidate group: ['groove', 'jam', 'rock', 'shred']\n",
      "\tTo enjoy oneself or be in harmony with a particular rhythm or music.\n",
      "\tto play music informally with others\n",
      "\tTo perform or play rock music.\n",
      "\tTo perform an activity, especially playing music or skateboarding, with great skill or intensity, like shredding a guitar solo.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "rw = find_recommendation(df)\n",
    "print(f\" type {type(rw)},\\nusing these words {rw[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 130)\n",
      "(130, 130)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[group metrics: 0.6668112426310061, 0.4548451189813011, 0.8192041282045356,0.14605518688265232\n",
       " root word: exhaust, group id: fb7dc317dbf562c0a79420118f823f50\n",
       " candidate group: ['drain', 'exhaust', 'sap', 'total']\n",
       " \tTo deplete or exhaust resources, energy, or vitality.\n",
       " \tTo drain of resources or strength; to wear out completely.\n",
       " \tTo drain someone of energy or vitality.\n",
       " \tTo destroy or wreck completely, especially in reference to vehicles.,\n",
       " group metrics: 0.6468176127874155, 0.4677014117419175, 0.8192041282045356,0.15792040975947702\n",
       " root word: tax, group id: 1832357b3b2db5fa0d8e1d7bbc25a7ab\n",
       " candidate group: ['drain', 'exhaust', 'sap', 'tax']\n",
       " \tTo deplete or exhaust resources, energy, or vitality.\n",
       " \tTo drain of resources or strength; to wear out completely.\n",
       " \tTo drain someone of energy or vitality.\n",
       " \tTo make heavy demands on someone’s resources or abilities, e.g., 'The difficult project taxed his patience.',\n",
       " group metrics: 0.6410907016394721, 0.4531656157622107, 0.8192041282045356,0.1636909237258528\n",
       " root word: sap, group id: 03fcf0339c681de880eaedad3c6ce82a\n",
       " candidate group: ['drain', 'empty', 'exhaust', 'sap']\n",
       " \tTo deplete or exhaust resources, energy, or vitality.\n",
       " \tto discharge or pour out\n",
       " \tTo drain of resources or strength; to wear out completely.\n",
       " \tTo drain someone of energy or vitality.,\n",
       " group metrics: 0.6410013668912845, 0.6186868245856227, 0.6851405493212731,0.021962175720038595\n",
       " root word: cube, group id: 2eb843fc0c3b5de51216fd6d6a38c385\n",
       " candidate group: ['cube', 'grain', 'shred', 'tip']\n",
       " \tA small piece of something, typically food, cut into a square shape.\n",
       " \tA single small particle or piece, such as of sand or salt.\n",
       " \tA small, thin piece that has been torn or cut from something larger, like a shred of paper.\n",
       " \tA small piece or end of something, like the tip of an iceberg.,\n",
       " group metrics: 0.6122381498040032, 0.5428332531233181, 0.7107942184505749,0.05206276478306876\n",
       " root word: shred, group id: 6b13db1e892c81417d2958289ab4546a\n",
       " candidate group: ['cube', 'grain', 'powder', 'shred']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo form into grains or granules.\n",
       " \tTo reduce a substance to fine particles by crushing or grinding.\n",
       " \tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.,\n",
       " group metrics: 0.5832894195098461, 0.5248302241774248, 0.7107942184505749,0.06136819777610336\n",
       " root word: groove, group id: 41671fee7635abfcb48bae2adc5e7c97\n",
       " candidate group: ['cube', 'grain', 'groove', 'shred']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo form into grains or granules.\n",
       " \tTo cut or form a groove in something.\n",
       " \tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.,\n",
       " group metrics: 0.5821507294843583, 0.4505040318022098, 0.7107942184505749,0.08023682560911559\n",
       " root word: cube, group id: 9af537d76b7547704df3eaec8faee430\n",
       " candidate group: ['cube', 'groove', 'powder', 'shred']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo cut or form a groove in something.\n",
       " \tTo reduce a substance to fine particles by crushing or grinding.\n",
       " \tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.,\n",
       " group metrics: 0.5665175571549194, 0.4505040318022098, 0.6296911868869787,0.05713679804145699\n",
       " root word: grain, group id: 9b3b952f608b07a1a0e68b3661689b8e\n",
       " candidate group: ['cube', 'grain', 'groove', 'powder']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo form into grains or granules.\n",
       " \tTo cut or form a groove in something.\n",
       " \tTo reduce a substance to fine particles by crushing or grinding.,\n",
       " group metrics: 0.549165592441618, 0.3892849462047492, 0.6821830908122153,0.12029488563244665\n",
       " root word: exhaust, group id: 41d44c7c3d219f1d35810aea83df36c4\n",
       " candidate group: ['drain', 'empty', 'exhaust', 'jam']\n",
       " \tTo remove liquid from something by causing it to flow out.\n",
       " \tto discharge or pour out\n",
       " \tTo let out or expel air or gas from a container or space.\n",
       " \tto squeeze or pack tightly into a space,\n",
       " group metrics: 0.5418542527821628, 0.45534444516200423, 0.6151571886484759,0.050598497770272303\n",
       " root word: jam, group id: fa7836ec92c593516be38a5b1cf8ec2c\n",
       " candidate group: ['groove', 'jam', 'rock', 'shred']\n",
       " \tTo enjoy oneself or be in harmony with a particular rhythm or music.\n",
       " \tto play music informally with others\n",
       " \tTo perform or play rock music.\n",
       " \tTo perform an activity, especially playing music or skateboarding, with great skill or intensity, like shredding a guitar solo.]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_list = get_candidate_words(df)\n",
    "candidate_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(prompt, model=\"gpt-4o\", temperature=0.7, max_tokens=4096):\n",
    "\n",
    "    # Initialize the OpenAI LLM with your API key and specify the GPT-4o model\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "    )\n",
    "    \n",
    "    result = llm.invoke(prompt)\n",
    "\n",
    "    return json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RecommendedGroup:\n",
    "    words: List[str]\n",
    "    connection_description: str\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Recommended Group: {self.words}\\nConnection Description: {self.connection_description}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_WORDS_SYSTEM_PROMPT =(\n",
    "    \"you are an expert in the nuance of the english language.\\n\\n\"\n",
    "    \"You will be given three words. you must determine if the three words can be related to a single topic.\\n\\n\"\n",
    "\n",
    "    \"To make that determination, do the following:\\n\"\n",
    "    \"* Determine common contexts for each word. \\n\"\n",
    "    \"* Determine if there is a context that is shared by all three words.\\n\"\n",
    "    \"* respond 'single' if a single topic can be found that applies to all three words, otherwise 'multiple'.\\n\"\n",
    "    \"* Provide an explanation for the response.\\n\\n\"\n",
    "    \n",
    "\n",
    "    \"return response in json with the key 'response' with the value 'single' or 'multiple' and the key 'explanation' with the reason for the response.\"\n",
    ")\n",
    "\n",
    "CREATE_GROUP_SYSTEM_PROMPT = \"\"\"\n",
    "you will be given a list called the \"anchor_words\".  These words share a \"common_connection\". \n",
    "\n",
    "You will be given list of \"candidate_words\", select the one word that is most higly connected to the \"anchor_words\".\n",
    "\n",
    "Steps:\n",
    "1. First identify the common connection that is present in all the \"anchor_words\".  If each word has multiple meanings, consider the meaning that is most common among the \"anchor_words\".\n",
    "\n",
    "2. Now test each word from the \"candidate_words\" and decide which one has the highest degree of connection to the \"anchor_words\".    \n",
    "\n",
    "3. Return the word that is most connected to the \"anchor_words\" and the reason for its selection in json structure.  The word should have the key \"word\" and the explanation should have the key \"explanation\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_away_analyzer(one_away_group: List[str], words_remaining: List[str]) -> List[Tuple[str, List[str]]]:\n",
    "    single_topic_groups = []\n",
    "    group_recommendations = []\n",
    "    possible_anchor_words_list = list(itertools.combinations(one_away_group, 3))\n",
    "\n",
    "    for anchor_list in possible_anchor_words_list:\n",
    "        # determine if the anchor words can be related to a single topic\n",
    "        anchor_words = \"\\n\\n\" + \", \".join(anchor_list)\n",
    "        prompt = [SystemMessage(ANCHOR_WORDS_SYSTEM_PROMPT), HumanMessage(anchor_words)]\n",
    "        response = chat_with_llm(prompt)\n",
    "\n",
    "        print(response)\n",
    "\n",
    "        if response[\"response\"] == \"single\":\n",
    "\n",
    "            single_topic_groups.append(\n",
    "                RecommendedGroup(words=anchor_list, connection_description=response[\"explanation\"])\n",
    "            )\n",
    "\n",
    "\n",
    "    for word_group in single_topic_groups:\n",
    "        # remove anchor words from the remaining word list\n",
    "        words_to_test = [x for x in words_remaining if x not in anchor_list]\n",
    "        user_prompt = \"\\n\\n anchor_words: \" + \", \".join(anchor_list) + \"\\n\\ncommon_connection: \" + response[\"explanation\"]\n",
    "        user_prompt += \"\\n\\n\" + \"candidate_words: \" + \", \".join(words_to_test)\n",
    "        prompt = [SystemMessage(CREATE_GROUP_SYSTEM_PROMPT), HumanMessage(user_prompt)]\n",
    "\n",
    "        response = chat_with_llm(prompt)\n",
    "        print(response)\n",
    "        new_group = list(word_group.words) + [response[\"word\"]]\n",
    "        group_recommendations.append(new_group)\n",
    " \n",
    "\n",
    "    return group_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_away_group = candidate_list[0].get_candidate_words()\n",
    "# one_away_group = ['groove', 'rock', 'shred', 'signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_remaining = df.word.unique().tolist()\n",
    "# words_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_remaining = [\"goodfella\", \"jaw\", \"answer\", \"handle\", \"park\", \"lemon\", \"yard\", \"field\", \"natural\", \"car\", \"harvard\", \"swinger\", \"green\", \"criminal\", \"address\", \"lawn\"]\n",
    "\n",
    "one_away_group = [\"green\", \"lawn\", \"field\", \"yard\"]\n",
    "# one_away_group = [\"address\", \"answer\", \"jaw\", \"handle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'single', 'explanation': \"The three words 'green,' 'lawn,' and 'field' can all be related to the single topic of 'outdoor spaces' or 'landscaping.' 'Green' is often used to describe the color of grass, which is a primary component of both 'lawns' and 'fields.' 'Lawn' refers to a managed area of grass, typically around homes or in parks, while 'field' can refer to a larger area of grass, often used for sports or agriculture. All three words share a common context in describing grassy, outdoor areas.\"}\n",
      "{'response': 'single', 'explanation': \"The words 'green', 'lawn', and 'yard' can all be related to a single topic: landscaping or outdoor spaces surrounding a home. 'Green' commonly refers to the color of healthy grass, 'lawn' is a common area covered with grass in a yard, and 'yard' is the general term for the outdoor area of a home, which often includes a lawn. Thus, these words can all be related to the topic of residential outdoor spaces or gardening.\"}\n",
      "{'response': 'single', 'explanation': \"The three words 'green', 'field', and 'yard' can all be related to the single topic of 'outdoor spaces'. 'Green' often describes the color of grass or plants, which are commonly found in outdoor settings. A 'field' is an open area of land, typically covered with grass, and is often associated with outdoor activities or agriculture. A 'yard' refers to a piece of land surrounding a house, usually covered with grass or landscaped, and is a common outdoor area. Therefore, they all share a common context related to outdoor, grassy spaces.\"}\n",
      "{'response': 'single', 'explanation': \"The words 'lawn', 'field', and 'yard' can all be related to the single topic of outdoor open spaces covered with grass. A 'lawn' typically refers to a managed area of grass around a home or building. A 'field' is a broader term that can refer to an open area of land that can be covered with grass or crops. A 'yard' is similar to a 'lawn' in that it often refers to the area surrounding a house, which can include a grass area. All three words share the common context of outdoor areas that are often grassy and open.\"}\n",
      "{'word': 'park', 'explanation': \"The word 'park' is closely related to the anchor words 'lawn', 'field', and 'yard' because it also refers to an outdoor open space that is often grassy. Parks are public areas that typically include grass and are designed for recreation and leisure, much like lawns and fields are open spaces that might be used for similar purposes. Therefore, 'park' shares the common context of being an outdoor open space, making it the most connected to the anchor words.\"}\n",
      "{'word': 'park', 'explanation': \"The word 'park' is most connected to the anchor words 'lawn', 'field', and 'yard' because it also refers to an outdoor open space that is often grassy. Parks are public areas that typically include grass and are designed for recreation and leisure, similar to lawns and fields. Thus, 'park' shares the common context of being an outdoor open space, making it the most connected to the anchor words.\"}\n",
      "{'word': 'park', 'explanation': \"The word 'park' is most connected to the anchor words 'lawn', 'field', and 'yard' because it also refers to an outdoor open space that is often grassy. Parks are public areas that typically include grass and are designed for recreation and leisure, similar to lawns and fields. Thus, 'park' shares the common context of being an outdoor open space, making it the most connected to the anchor words.\"}\n",
      "{'word': 'park', 'explanation': \"The word 'park' is most connected to the anchor words 'lawn', 'field', and 'yard' because it also refers to an outdoor open space that is often grassy. Parks are public areas that typically include grass and are designed for recreation and leisure, similar to lawns and fields. Thus, 'park' shares the common context of being an outdoor open space, making it the most connected to the anchor words.\"}\n",
      "response from one away analyzer\n",
      "['green', 'lawn', 'field', 'park']\n",
      "['green', 'lawn', 'yard', 'park']\n",
      "['green', 'field', 'yard', 'park']\n",
      "['lawn', 'field', 'yard', 'park']\n"
     ]
    }
   ],
   "source": [
    "r = one_away_analyzer(one_away_group, words_remaining)\n",
    "\n",
    "print(\"response from one away analyzer\")\n",
    "for group in r:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['green', 'field', 'yard', 'park']\n"
     ]
    }
   ],
   "source": [
    "# make sure the group is not previously known to be invalid\n",
    "\n",
    "\n",
    "# select one of the list elements by random\n",
    "selected_group = random.choice(r)\n",
    "\n",
    "print(selected_group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
