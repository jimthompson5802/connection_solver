{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python311.zip\n",
      "/usr/local/lib/python3.11\n",
      "/usr/local/lib/python3.11/lib-dynload\n",
      "\n",
      "/usr/local/lib/python3.11/site-packages\n",
      "/workspaces/connection_solver/src/agent\n",
      "/workspaces/connection_solver/src/agent\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import hashlib\n",
    "import itertools\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# import cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Import the 'rag_tools' module from the 'agent' directory\n",
    "current_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the 'agent' directory to the sys.path\n",
    "other_dir = os.path.join(project_dir, 'agent')\n",
    "sys.path.append(other_dir)\n",
    "\n",
    "# confirm the 'agent' directory is in the sys.path\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "\n",
    "from embedvec_tools import choose_embedvec_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/openai/api_key.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_id(group: List[str]) -> str:\n",
    "        return hashlib.md5(\"\".join(sorted(group)).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vocab = \"word_list6.pkl\"\n",
    "\n",
    "# load the vocabulary\n",
    "df = pd.read_pickle(test_vocab)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConnectionGroup:\n",
    "    group_metric: float = field(default=0.0, metadata={\"help\": \"Average cosine similarity of all combinations of words in the group\"})\n",
    "    group_metric_min: float = field(default=0.0, metadata={\"help\": \"Minimum cosine similarity of all combinations of words in the group\"})\n",
    "    group_metric_max: float = field(default=0.0, metadata={\"help\": \"Maximum cosine similarity of all combinations of words in the group\"})\n",
    "    group_metric_std: float = field(default=0.0, metadata={\"help\": \"Standard deviation of cosine similarity of all combinations of words in the group\"})\n",
    "    root_word: str = field(default=\"\", metadata={\"help\": \"Root word of the group\"})\n",
    "    candidate_pairs: list = field(default_factory=list, metadata={\"help\": \"List of candidate word with definition\"})\n",
    "    group_id: Optional[str] = field(default=None, metadata={\"help\": \"Checksum identifer for the group\"})\n",
    "\n",
    "    def add_entry(self, word, connection):\n",
    "        if len(self.candidate_pairs) < 4:\n",
    "            self.candidate_pairs.append((word, connection))\n",
    "            if len(self.candidate_pairs) == 4:\n",
    "                self.group_id = self._compute_group_id()\n",
    "        else:\n",
    "            raise ValueError(\"Group is full, cannot add more entries\")          \n",
    "\n",
    "    def get_candidate_words(self):\n",
    "        sorted_pairs = sorted(self.candidate_pairs, key=lambda x:x[0])\n",
    "        return [x[0] for x in sorted_pairs]\n",
    "    \n",
    "    def get_candidate_connections(self):\n",
    "        sorted_pairs = sorted(self.candidate_pairs, key=lambda x:x[0])\n",
    "\n",
    "        # strip the part of speech tag at the beginning of the connection, which looks like \"noun:\" or \"verb:\" etc.\n",
    "        # find the first colon and take the substring after it\n",
    "        stripped_connections = [x[1].split(':', 1)[1].strip() if ':' in x[1] else x[1] for x in sorted_pairs]\n",
    "\n",
    "        return stripped_connections\n",
    "    \n",
    "    def _compute_group_id(self):\n",
    "        return hashlib.md5(\"\".join(self.get_candidate_words()).encode()).hexdigest()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return_string = f\"group metrics: {self.group_metric}, {self.group_metric_min}, {self.group_metric_max},{self.group_metric_std}\\n\"\n",
    "        return_string += f\"root word: {self.root_word}, group id: {self.group_id}\\n\"\n",
    "        return_string += f\"candidate group: {self.get_candidate_words()}\\n\"\n",
    "        for connection in self.get_candidate_connections():\n",
    "            return_string += f\"\\t{connection}\\n\"\n",
    "\n",
    "        return return_string\n",
    "    \n",
    "    # method to determine if the group is equal to another group\n",
    "    def __eq__(self, other):\n",
    "        return set(self.get_candidate_words()) == set(other.get_candidate_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A small, hard seed of a cereal plant, su...</td>\n",
       "      <td>[-0.012600858695805073, 0.012784576043486595, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A single small particle or piece, such a...</td>\n",
       "      <td>[0.020823834463953972, -0.024603812023997307, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: The texture or pattern of fibers in wood...</td>\n",
       "      <td>[-0.007330888416618109, -0.0005790892755612731...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: An individual element or component withi...</td>\n",
       "      <td>[0.025177670642733574, 0.00015151509433053434,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A unit of weight in the avoirdupois syst...</td>\n",
       "      <td>[0.01975935325026512, -0.03580138459801674, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A characteristic or essential quality.</td>\n",
       "      <td>[0.019196202978491783, -0.0004823370254598558,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: A small amount or degree, e.g., 'a grain...</td>\n",
       "      <td>[-0.0131387859582901, 0.02310130186378956, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grain</td>\n",
       "      <td>noun: The alignment or direction of the fibers...</td>\n",
       "      <td>[-0.017064416781067848, 0.010718798264861107, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grain</td>\n",
       "      <td>verb: To form into grains or granules.</td>\n",
       "      <td>[-0.01263611763715744, 0.011555520817637444, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grain</td>\n",
       "      <td>verb: To give a texture resembling grain to a ...</td>\n",
       "      <td>[-0.012740093283355236, 0.005322569981217384, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grain</td>\n",
       "      <td>adjective: Relating to or resembling grain.</td>\n",
       "      <td>[-0.040710438042879105, 0.025842908769845963, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>drain</td>\n",
       "      <td>noun: A pipe or channel that carries away wast...</td>\n",
       "      <td>[0.029757274314761162, 0.013937382027506828, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drain</td>\n",
       "      <td>noun: An instance of water or liquid flowing o...</td>\n",
       "      <td>[0.014105943962931633, 0.05353502556681633, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>drain</td>\n",
       "      <td>noun: A reduction or depletion of resources or...</td>\n",
       "      <td>[0.019143683835864067, 0.049778468906879425, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>drain</td>\n",
       "      <td>verb: To cause liquid to flow away from someth...</td>\n",
       "      <td>[0.0020029456354677677, 0.010084928013384342, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word                                         definition  \\\n",
       "0   grain  noun: A small, hard seed of a cereal plant, su...   \n",
       "1   grain  noun: A single small particle or piece, such a...   \n",
       "2   grain  noun: The texture or pattern of fibers in wood...   \n",
       "3   grain  noun: An individual element or component withi...   \n",
       "4   grain  noun: A unit of weight in the avoirdupois syst...   \n",
       "5   grain       noun: A characteristic or essential quality.   \n",
       "6   grain  noun: A small amount or degree, e.g., 'a grain...   \n",
       "7   grain  noun: The alignment or direction of the fibers...   \n",
       "8   grain             verb: To form into grains or granules.   \n",
       "9   grain  verb: To give a texture resembling grain to a ...   \n",
       "10  grain        adjective: Relating to or resembling grain.   \n",
       "11  drain  noun: A pipe or channel that carries away wast...   \n",
       "12  drain  noun: An instance of water or liquid flowing o...   \n",
       "13  drain  noun: A reduction or depletion of resources or...   \n",
       "14  drain  verb: To cause liquid to flow away from someth...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.012600858695805073, 0.012784576043486595, ...  \n",
       "1   [0.020823834463953972, -0.024603812023997307, ...  \n",
       "2   [-0.007330888416618109, -0.0005790892755612731...  \n",
       "3   [0.025177670642733574, 0.00015151509433053434,...  \n",
       "4   [0.01975935325026512, -0.03580138459801674, -0...  \n",
       "5   [0.019196202978491783, -0.0004823370254598558,...  \n",
       "6   [-0.0131387859582901, 0.02310130186378956, -0....  \n",
       "7   [-0.017064416781067848, 0.010718798264861107, ...  \n",
       "8   [-0.01263611763715744, 0.011555520817637444, -...  \n",
       "9   [-0.012740093283355236, 0.005322569981217384, ...  \n",
       "10  [-0.040710438042879105, 0.025842908769845963, ...  \n",
       "11  [0.029757274314761162, 0.013937382027506828, -...  \n",
       "12  [0.014105943962931633, 0.05353502556681633, -0...  \n",
       "13  [0.019143683835864067, 0.049778468906879425, -...  \n",
       "14  [0.0020029456354677677, 0.010084928013384342, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_words(df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Generate a list of candidate word groups based on cosine similarity of their embeddings.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing words and their corresponding embeddings. Dataframe should have two columns: 'word', 'definition' and 'embedding', in that order.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique candidate word groups sorted by their group metric in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "    candidate_list = []\n",
    "\n",
    "    # create cosine similarity matrix for all pairs of the vectors\n",
    "    cosine_similarities = cosine_similarity(df['embedding'].tolist())\n",
    "    print(cosine_similarities.shape)\n",
    "\n",
    "    # for each row in the cosine similarity matrix, sort by the cosine similarity\n",
    "    sorted_cosine_similarites = np.argsort(cosine_similarities, axis=1)\n",
    "    print(sorted_cosine_similarites.shape)\n",
    "\n",
    "    # group of words that are most similar to each other\n",
    "    for r in range(df.shape[0]):\n",
    "\n",
    "        # get the top 3 closest words that are not the same as the current word and are not already connected\n",
    "        connected_words = set()\n",
    "        top3 = []\n",
    "        for i in range(sorted_cosine_similarites.shape[1]-2, 0, -1):\n",
    "            c = sorted_cosine_similarites[r, i]\n",
    "            \n",
    "            # make sure the word is not already connected and not the current word\n",
    "            if df.iloc[c, 0] not in connected_words and df.iloc[c, 0] != df.iloc[r, 0]:\n",
    "                connected_words.add(df.iloc[c, 0])\n",
    "                top3.append(c)\n",
    "            if len(connected_words) == 3:\n",
    "                break   \n",
    "\n",
    "        # create candidate group for the current word and the top 3 closest words\n",
    "        if df.iloc[r, 0] not in connected_words and len(connected_words) == 3:\n",
    "            candidate_group = ConnectionGroup()\n",
    "            candidate_group.root_word = df.iloc[r, 0]\n",
    "            candidate_group.add_entry(df.iloc[r, 0], df.iloc[r, 1])\n",
    "            \n",
    "            for c in top3:\n",
    "                candidate_group.add_entry(df.iloc[c, 0], df.iloc[c, 1])\n",
    "\n",
    "            combinations = list(itertools.combinations([r] + top3, 2))\n",
    "            candidate_group.group_metric= np.array([cosine_similarities[r, c] for r,c in combinations]).mean()\n",
    "            candidate_group.group_metric_min = np.array([cosine_similarities[r, c] for r,c in combinations]).min()\n",
    "            candidate_group.group_metric_max = np.array([cosine_similarities[r, c] for r,c in combinations]).max()\n",
    "            candidate_group.group_metric_std = np.array([cosine_similarities[r, c] for r,c in combinations]).std()\n",
    "\n",
    "            candidate_list.append(candidate_group)\n",
    "\n",
    "    # sort the candidate list by the group metric in descending order\n",
    "    candidate_list.sort(key=lambda x: x.group_metric, reverse=True)\n",
    "\n",
    "    # remove duplicate groups\n",
    "    found_groups = set()\n",
    "    unique_candidate_list = []\n",
    "    for candidate in candidate_list:\n",
    "        if candidate.group_id not in found_groups:\n",
    "            unique_candidate_list.append(candidate)\n",
    "            found_groups.add(candidate.group_id)\n",
    "\n",
    "    return unique_candidate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grain',\n",
       " 'drain',\n",
       " 'total',\n",
       " 'cube',\n",
       " 'syrup',\n",
       " 'shred',\n",
       " 'signature',\n",
       " 'sap',\n",
       " 'jam',\n",
       " 'tax',\n",
       " 'powder',\n",
       " 'rock',\n",
       " 'empty',\n",
       " 'groove',\n",
       " 'tip',\n",
       " 'exhaust']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recommendation(df: pd.DataFrame) -> Tuple[List[str], Dict[str, Any]]:\n",
    "    candidate_list = get_candidate_words(df)\n",
    "    print(len(candidate_list))\n",
    "    # list_to_validate = \"\\n\".join([str(x) for x in candidate_list[:5]])\n",
    "    # recommended_group = choose_embedvec_item(list_to_validate)\n",
    "    # print(recommended_group)\n",
    "    # recommended_words = recommended_group[\"candidate_group\"]\n",
    "    # # print(recommended_words)\n",
    "    \n",
    "    return candidate_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage:\n",
    "while df.word.unique().size > 0:\n",
    "    rw = find_recommendation(df)\n",
    "    print(f\"using these words {rw}, type {type(rw)}\")\n",
    "\n",
    "    # remove the words from the dataframe\n",
    "    df = df[~df.word.isin(rw)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.word.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "candidate_list = get_candidate_words(df)\n",
    "for candidate in candidate_list:\n",
    "    if candidate.group_id in answers:\n",
    "        print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 130)\n",
      "(130, 130)\n",
      "89\n",
      " type <class 'list'>,\n",
      "using these words [group metrics: 0.6668112426310061, 0.4548451189813011, 0.8192041282045356,0.14605518688265232\n",
      "root word: exhaust, group id: fb7dc317dbf562c0a79420118f823f50\n",
      "candidate group: ['drain', 'exhaust', 'sap', 'total']\n",
      "\tTo deplete or exhaust resources, energy, or vitality.\n",
      "\tTo drain of resources or strength; to wear out completely.\n",
      "\tTo drain someone of energy or vitality.\n",
      "\tTo destroy or wreck completely, especially in reference to vehicles.\n",
      ", group metrics: 0.6468176127874155, 0.4677014117419175, 0.8192041282045356,0.15792040975947702\n",
      "root word: tax, group id: 1832357b3b2db5fa0d8e1d7bbc25a7ab\n",
      "candidate group: ['drain', 'exhaust', 'sap', 'tax']\n",
      "\tTo deplete or exhaust resources, energy, or vitality.\n",
      "\tTo drain of resources or strength; to wear out completely.\n",
      "\tTo drain someone of energy or vitality.\n",
      "\tTo make heavy demands on someone’s resources or abilities, e.g., 'The difficult project taxed his patience.'\n",
      ", group metrics: 0.6410907016394721, 0.4531656157622107, 0.8192041282045356,0.1636909237258528\n",
      "root word: sap, group id: 03fcf0339c681de880eaedad3c6ce82a\n",
      "candidate group: ['drain', 'empty', 'exhaust', 'sap']\n",
      "\tTo deplete or exhaust resources, energy, or vitality.\n",
      "\tto discharge or pour out\n",
      "\tTo drain of resources or strength; to wear out completely.\n",
      "\tTo drain someone of energy or vitality.\n",
      ", group metrics: 0.6410013668912845, 0.6186868245856227, 0.6851405493212731,0.021962175720038595\n",
      "root word: cube, group id: 2eb843fc0c3b5de51216fd6d6a38c385\n",
      "candidate group: ['cube', 'grain', 'shred', 'tip']\n",
      "\tA small piece of something, typically food, cut into a square shape.\n",
      "\tA single small particle or piece, such as of sand or salt.\n",
      "\tA small, thin piece that has been torn or cut from something larger, like a shred of paper.\n",
      "\tA small piece or end of something, like the tip of an iceberg.\n",
      ", group metrics: 0.6122381498040032, 0.5428332531233181, 0.7107942184505749,0.05206276478306876\n",
      "root word: shred, group id: 6b13db1e892c81417d2958289ab4546a\n",
      "candidate group: ['cube', 'grain', 'powder', 'shred']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo form into grains or granules.\n",
      "\tTo reduce a substance to fine particles by crushing or grinding.\n",
      "\tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.\n",
      ", group metrics: 0.5832894195098461, 0.5248302241774248, 0.7107942184505749,0.06136819777610336\n",
      "root word: groove, group id: 41671fee7635abfcb48bae2adc5e7c97\n",
      "candidate group: ['cube', 'grain', 'groove', 'shred']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo form into grains or granules.\n",
      "\tTo cut or form a groove in something.\n",
      "\tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.\n",
      ", group metrics: 0.5821507294843583, 0.4505040318022098, 0.7107942184505749,0.08023682560911559\n",
      "root word: cube, group id: 9af537d76b7547704df3eaec8faee430\n",
      "candidate group: ['cube', 'groove', 'powder', 'shred']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo cut or form a groove in something.\n",
      "\tTo reduce a substance to fine particles by crushing or grinding.\n",
      "\tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.\n",
      ", group metrics: 0.5665175571549194, 0.4505040318022098, 0.6296911868869787,0.05713679804145699\n",
      "root word: grain, group id: 9b3b952f608b07a1a0e68b3661689b8e\n",
      "candidate group: ['cube', 'grain', 'groove', 'powder']\n",
      "\tTo cut or shape something into small square pieces or cubes.\n",
      "\tTo form into grains or granules.\n",
      "\tTo cut or form a groove in something.\n",
      "\tTo reduce a substance to fine particles by crushing or grinding.\n",
      ", group metrics: 0.549165592441618, 0.3892849462047492, 0.6821830908122153,0.12029488563244665\n",
      "root word: exhaust, group id: 41d44c7c3d219f1d35810aea83df36c4\n",
      "candidate group: ['drain', 'empty', 'exhaust', 'jam']\n",
      "\tTo remove liquid from something by causing it to flow out.\n",
      "\tto discharge or pour out\n",
      "\tTo let out or expel air or gas from a container or space.\n",
      "\tto squeeze or pack tightly into a space\n",
      ", group metrics: 0.5418542527821628, 0.45534444516200423, 0.6151571886484759,0.050598497770272303\n",
      "root word: jam, group id: fa7836ec92c593516be38a5b1cf8ec2c\n",
      "candidate group: ['groove', 'jam', 'rock', 'shred']\n",
      "\tTo enjoy oneself or be in harmony with a particular rhythm or music.\n",
      "\tto play music informally with others\n",
      "\tTo perform or play rock music.\n",
      "\tTo perform an activity, especially playing music or skateboarding, with great skill or intensity, like shredding a guitar solo.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "rw = find_recommendation(df)\n",
    "print(f\" type {type(rw)},\\nusing these words {rw[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 130)\n",
      "(130, 130)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[group metrics: 0.6668112426310061, 0.4548451189813011, 0.8192041282045356,0.14605518688265232\n",
       " root word: exhaust, group id: fb7dc317dbf562c0a79420118f823f50\n",
       " candidate group: ['drain', 'exhaust', 'sap', 'total']\n",
       " \tTo deplete or exhaust resources, energy, or vitality.\n",
       " \tTo drain of resources or strength; to wear out completely.\n",
       " \tTo drain someone of energy or vitality.\n",
       " \tTo destroy or wreck completely, especially in reference to vehicles.,\n",
       " group metrics: 0.6468176127874155, 0.4677014117419175, 0.8192041282045356,0.15792040975947702\n",
       " root word: tax, group id: 1832357b3b2db5fa0d8e1d7bbc25a7ab\n",
       " candidate group: ['drain', 'exhaust', 'sap', 'tax']\n",
       " \tTo deplete or exhaust resources, energy, or vitality.\n",
       " \tTo drain of resources or strength; to wear out completely.\n",
       " \tTo drain someone of energy or vitality.\n",
       " \tTo make heavy demands on someone’s resources or abilities, e.g., 'The difficult project taxed his patience.',\n",
       " group metrics: 0.6410907016394721, 0.4531656157622107, 0.8192041282045356,0.1636909237258528\n",
       " root word: sap, group id: 03fcf0339c681de880eaedad3c6ce82a\n",
       " candidate group: ['drain', 'empty', 'exhaust', 'sap']\n",
       " \tTo deplete or exhaust resources, energy, or vitality.\n",
       " \tto discharge or pour out\n",
       " \tTo drain of resources or strength; to wear out completely.\n",
       " \tTo drain someone of energy or vitality.,\n",
       " group metrics: 0.6410013668912845, 0.6186868245856227, 0.6851405493212731,0.021962175720038595\n",
       " root word: cube, group id: 2eb843fc0c3b5de51216fd6d6a38c385\n",
       " candidate group: ['cube', 'grain', 'shred', 'tip']\n",
       " \tA small piece of something, typically food, cut into a square shape.\n",
       " \tA single small particle or piece, such as of sand or salt.\n",
       " \tA small, thin piece that has been torn or cut from something larger, like a shred of paper.\n",
       " \tA small piece or end of something, like the tip of an iceberg.,\n",
       " group metrics: 0.6122381498040032, 0.5428332531233181, 0.7107942184505749,0.05206276478306876\n",
       " root word: shred, group id: 6b13db1e892c81417d2958289ab4546a\n",
       " candidate group: ['cube', 'grain', 'powder', 'shred']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo form into grains or granules.\n",
       " \tTo reduce a substance to fine particles by crushing or grinding.\n",
       " \tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.,\n",
       " group metrics: 0.5832894195098461, 0.5248302241774248, 0.7107942184505749,0.06136819777610336\n",
       " root word: groove, group id: 41671fee7635abfcb48bae2adc5e7c97\n",
       " candidate group: ['cube', 'grain', 'groove', 'shred']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo form into grains or granules.\n",
       " \tTo cut or form a groove in something.\n",
       " \tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.,\n",
       " group metrics: 0.5821507294843583, 0.4505040318022098, 0.7107942184505749,0.08023682560911559\n",
       " root word: cube, group id: 9af537d76b7547704df3eaec8faee430\n",
       " candidate group: ['cube', 'groove', 'powder', 'shred']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo cut or form a groove in something.\n",
       " \tTo reduce a substance to fine particles by crushing or grinding.\n",
       " \tTo cut or tear something into small, thin pieces, such as to shred documents or vegetables.,\n",
       " group metrics: 0.5665175571549194, 0.4505040318022098, 0.6296911868869787,0.05713679804145699\n",
       " root word: grain, group id: 9b3b952f608b07a1a0e68b3661689b8e\n",
       " candidate group: ['cube', 'grain', 'groove', 'powder']\n",
       " \tTo cut or shape something into small square pieces or cubes.\n",
       " \tTo form into grains or granules.\n",
       " \tTo cut or form a groove in something.\n",
       " \tTo reduce a substance to fine particles by crushing or grinding.,\n",
       " group metrics: 0.549165592441618, 0.3892849462047492, 0.6821830908122153,0.12029488563244665\n",
       " root word: exhaust, group id: 41d44c7c3d219f1d35810aea83df36c4\n",
       " candidate group: ['drain', 'empty', 'exhaust', 'jam']\n",
       " \tTo remove liquid from something by causing it to flow out.\n",
       " \tto discharge or pour out\n",
       " \tTo let out or expel air or gas from a container or space.\n",
       " \tto squeeze or pack tightly into a space,\n",
       " group metrics: 0.5418542527821628, 0.45534444516200423, 0.6151571886484759,0.050598497770272303\n",
       " root word: jam, group id: fa7836ec92c593516be38a5b1cf8ec2c\n",
       " candidate group: ['groove', 'jam', 'rock', 'shred']\n",
       " \tTo enjoy oneself or be in harmony with a particular rhythm or music.\n",
       " \tto play music informally with others\n",
       " \tTo perform or play rock music.\n",
       " \tTo perform an activity, especially playing music or skateboarding, with great skill or intensity, like shredding a guitar solo.]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_list = get_candidate_words(df)\n",
    "candidate_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(prompt, model=\"gpt-4o\", temperature=0.7, max_tokens=4096):\n",
    "\n",
    "    # Initialize the OpenAI LLM with your API key and specify the GPT-4o model\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "    )\n",
    "    \n",
    "    result = llm.invoke(prompt)\n",
    "\n",
    "    return json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_away_group = candidate_list[0].get_candidate_words()\n",
    "# one_away_group = ['groove', 'rock', 'shred', 'signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grain',\n",
       " 'drain',\n",
       " 'total',\n",
       " 'cube',\n",
       " 'syrup',\n",
       " 'shred',\n",
       " 'signature',\n",
       " 'sap',\n",
       " 'jam',\n",
       " 'tax',\n",
       " 'powder',\n",
       " 'rock',\n",
       " 'empty',\n",
       " 'groove',\n",
       " 'tip',\n",
       " 'exhaust']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_remaining = df.word.unique().tolist()\n",
    "words_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_remaining = [\"goodfella\", \"jaw\", \"answer\", \"handle\", \"park\", \"lemon\", \"yard\", \"field\", \"natural\", \"car\", \"harvard\", \"swinger\", \"green\", \"criminal\", \"address\", \"lawn\"]\n",
    "\n",
    "# # one_away_group = [\"green\", \"lawn\", \"field\", \"yard\"]\n",
    "# one_away_group = [\"address\", \"answer\", \"jaw\", \"handle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drain', 'exhaust', 'sap'),\n",
       " ('drain', 'exhaust', 'total'),\n",
       " ('drain', 'sap', 'total'),\n",
       " ('exhaust', 'sap', 'total')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all combinations of 3 words from the list\n",
    "possible_anchor_words_list = list(itertools.combinations(one_away_group, 3))\n",
    "possible_anchor_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are an expert in the nuance of the english language.\n",
      "\n",
      "You will be given three words. you must determine if the three words can be related to a single topic.\n",
      "\n",
      "To make that determination, do the following:\n",
      "* Determine common contexts for each word. \n",
      "* Determine if there is a context that is shared by all three words.\n",
      "* respond 'single' if a single topic can be found that applies to all three words, otherwise 'multiple'.\n",
      "* Provide an explanation for the response.\n",
      "\n",
      "return response in json with the key 'response' with the value 'single' or 'multiple' and the key 'explanation' with the reason for the response.\n"
     ]
    }
   ],
   "source": [
    "system_prompt =(\n",
    "    \"you are an expert in the nuance of the english language.\\n\\n\"\n",
    "    \"You will be given three words. you must determine if the three words can be related to a single topic.\\n\\n\"\n",
    "\n",
    "    \"To make that determination, do the following:\\n\"\n",
    "    \"* Determine common contexts for each word. \\n\"\n",
    "    \"* Determine if there is a context that is shared by all three words.\\n\"\n",
    "    \"* respond 'single' if a single topic can be found that applies to all three words, otherwise 'multiple'.\\n\"\n",
    "    \"* Provide an explanation for the response.\\n\\n\"\n",
    "    \n",
    "\n",
    "    \"return response in json with the key 'response' with the value 'single' or 'multiple' and the key 'explanation' with the reason for the response.\"\n",
    ")\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt2 = \"\"\"\n",
    "you will be given a list called the \"anchor_words\".  These words share a \"common_connection\". \n",
    "\n",
    "You will be given list of \"candidate_words\", select the one word that is most higly connected to the \"anchor_words\".\n",
    "\n",
    "Steps:\n",
    "1. First identify the common connection that is present in all the \"anchor_words\".  If each word has multiple meanings, consider the meaning that is most common among the \"anchor_words\".\n",
    "\n",
    "2. Now test each word from the \"candidate_words\" and decide which one has the highest degree of connection to the \"anchor_words\".    \n",
    "\n",
    "3. Return the word that is most connected to the \"anchor_words\" and the reason for its selection in json structure.  The word should have the key \"word\" and the explanation should have the key \"explanation\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " you are an expert in the nuance of the english language.\n",
      "\n",
      "You will be given three words. you must determine if the three words can be related to a single topic.\n",
      "\n",
      "To make that determination, do the following:\n",
      "* Determine common contexts for each word. \n",
      "* Determine if there is a context that is shared by all three words.\n",
      "* respond 'single' if a single topic can be found that applies to all three words, otherwise 'multiple'.\n",
      "* Provide an explanation for the response.\n",
      "\n",
      "return response in json with the key 'response' with the value 'single' or 'multiple' and the key 'explanation' with the reason for the response. \n",
      "\n",
      "drain, exhaust, sap\n",
      "single concept: ('drain', 'exhaust', 'sap'), All three words can be related to the single topic of depletion or reduction of resources. 'Drain' often refers to removing or depleting liquid or resources from something. 'Exhaust' is commonly used to describe the act of using up resources, energy, or supplies completely. 'Sap' can mean to gradually weaken or deplete energy or vitality. Therefore, they all share the context of causing a decrease or depletion, whether it's energy, resources, or vitality.\n",
      "\n",
      "\n",
      " you are an expert in the nuance of the english language.\n",
      "\n",
      "You will be given three words. you must determine if the three words can be related to a single topic.\n",
      "\n",
      "To make that determination, do the following:\n",
      "* Determine common contexts for each word. \n",
      "* Determine if there is a context that is shared by all three words.\n",
      "* respond 'single' if a single topic can be found that applies to all three words, otherwise 'multiple'.\n",
      "* Provide an explanation for the response.\n",
      "\n",
      "return response in json with the key 'response' with the value 'single' or 'multiple' and the key 'explanation' with the reason for the response. \n",
      "\n",
      "drain, exhaust, total\n",
      "multiple concepts: ('drain', 'exhaust', 'total'), The word 'drain' can be related to removing liquid, reducing resources or energy, or the action of emptying something. 'Exhaust' can refer to the emission of gases from an engine, using up resources or energy, or feeling completely worn out. 'Total' generally refers to the complete amount or sum of something. While 'drain' and 'exhaust' can share a context of depletion or usage of resources, 'total' does not fit neatly into this context as it is more about a summation or entirety rather than depletion. Therefore, there is no single topic that encompasses all three words simultaneously.\n",
      "\n",
      "\n",
      " you are an expert in the nuance of the english language.\n",
      "\n",
      "You will be given three words. you must determine if the three words can be related to a single topic.\n",
      "\n",
      "To make that determination, do the following:\n",
      "* Determine common contexts for each word. \n",
      "* Determine if there is a context that is shared by all three words.\n",
      "* respond 'single' if a single topic can be found that applies to all three words, otherwise 'multiple'.\n",
      "* Provide an explanation for the response.\n",
      "\n",
      "return response in json with the key 'response' with the value 'single' or 'multiple' and the key 'explanation' with the reason for the response. \n",
      "\n",
      "drain, sap, total\n",
      "multiple concepts: ('drain', 'sap', 'total'), The three words 'drain,' 'sap,' and 'total' do not share a single context that applies to all of them. 'Drain' often refers to removing liquid or energy from something, as in draining water or resources. 'Sap' can mean to weaken or deplete, such as sapping strength or energy, and also refers to the fluid in plants. 'Total' typically refers to the complete amount or sum. While 'drain' and 'sap' can loosely relate to depletion, 'total' does not share a direct contextual link with the idea of depletion or removal, as it often refers to an aggregate or complete amount. Therefore, these words relate to different contexts, making it difficult to find a single topic that encompasses all three.\n",
      "\n",
      "\n",
      " you are an expert in the nuance of the english language.\n",
      "\n",
      "You will be given three words. you must determine if the three words can be related to a single topic.\n",
      "\n",
      "To make that determination, do the following:\n",
      "* Determine common contexts for each word. \n",
      "* Determine if there is a context that is shared by all three words.\n",
      "* respond 'single' if a single topic can be found that applies to all three words, otherwise 'multiple'.\n",
      "* Provide an explanation for the response.\n",
      "\n",
      "return response in json with the key 'response' with the value 'single' or 'multiple' and the key 'explanation' with the reason for the response. \n",
      "\n",
      "exhaust, sap, total\n",
      "multiple concepts: ('exhaust', 'sap', 'total'), The words 'exhaust,' 'sap,' and 'total' do not have a single context that ties them all together. 'Exhaust' can mean to tire out or deplete resources, often used in contexts of energy or resources. 'Sap' can mean to gradually weaken or also refer to the fluid in plants, and its context could be biological or metaphorical. 'Total' generally indicates a complete amount or sum and is often used in mathematical or comprehensive contexts. While 'exhaust' and 'sap' can both be related to the concept of depletion or weakening, 'total' does not share this context and is more focused on completeness or entirety. Therefore, a single topic does not encompass all three.\n"
     ]
    }
   ],
   "source": [
    "for anchor_list in possible_anchor_words_list:\n",
    "    anchor_words = \"\\n\\n\" + \", \".join(anchor_list)\n",
    "\n",
    "    prompt = [SystemMessage(system_prompt), HumanMessage(anchor_words)]\n",
    "\n",
    "    print(\"\\n\\n\", prompt[0].content, prompt[1].content)\n",
    "\n",
    "    response = chat_with_llm(prompt)\n",
    "    \n",
    "    if response[\"response\"] == \"single\":\n",
    "    #     # remove anchor words from the remaining word list\n",
    "        print(f\"single concept: {anchor_list}, {response['explanation']}\")\n",
    "    #     words_to_test = [x for x in words_remaining if x not in anchor_list]\n",
    "    #     user_prompt = \"\\n\\n anchor_words: \" + \", \".join(anchor_list) + \"\\n\\ncommon_connection: \" + response[\"explanation\"]\n",
    "    #     user_prompt += \"\\n\\n\" + \"candidate_words: \" + \", \".join(words_to_test)\n",
    "    #     prompt = [SystemMessage(system_prompt2), HumanMessage(user_prompt)]\n",
    "    #     print(\"\\n\\n\", prompt[0].content, prompt[1].content)\n",
    "    #     response = chat_with_llm(prompt)\n",
    "    #     print(response)\n",
    "    else:\n",
    "        print(f\"multiple concepts: {anchor_list}, {response['explanation']}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
